{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data = pickle.load(fo, encoding='bytes')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the CIFAR-10\n",
    "def load_CIFAR10(pos, n_chunks=1):\n",
    "    Xtr = []\n",
    "    Ytr = []\n",
    "    for i in range(n_chunks):\n",
    "        train = unpickle(pos + '/data_batch_{0}'.format(i + 1))\n",
    "        Xtr.extend(train[b'data'])\n",
    "        Ytr.extend(train[b'labels'])\n",
    "        test = unpickle(pos + '/test_batch')\n",
    "        Xte = test[b'data']\n",
    "        Yte = test[b'labels']\n",
    "    return np.array(Xtr), np.array(Ytr), np.array(Xte), np.array(Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expresses the label data in one-hot encoding.\n",
    "def onehot_encoding (Ytr, Yte):\n",
    "    Ytr_onehot = np.zeros((Ytr.size, 10))\n",
    "    Yte_onehot = np.zeros((Yte.size, 10))\n",
    "    for i in range(Ytr.size):\n",
    "        Ytr_onehot[i][Ytr[i]] = 1\n",
    "    for i in range(Yte.size):\n",
    "        Yte_onehot[i][Yte[i]] = 1\n",
    "    return Ytr_onehot, Yte_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train and test data\n",
    "Xtr, Ytr, Xte, Yte = load_CIFAR10('cifar-10-batches-py', 5)\n",
    "                                 \n",
    "# image data, each data size is 32*32*3\n",
    "Xtr = Xtr.reshape(50000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "Xte= Xte.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "\n",
    "# label data of train and test data, label data is represented by one-hot encoding\n",
    "Ytr_onehot, Yte_onehot = onehot_encoding(Ytr, Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "    Y = tf.placeholder(tf.float32, [None, 10])\n",
    "    dropout_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the layers of CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Conv-1'):\n",
    "    W1 = tf.Variable(tf.random_normal([3, 3, 3, 32], stddev=0.01))\n",
    "    # padding='SAME' keeps output size equal to input\n",
    "    L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    # Batch normalization\n",
    "    batch_mean, batch_var = tf.nn.moments(L1, [0])\n",
    "    scale = tf.Variable(tf.ones([32, 32, 32]))\n",
    "    beta = tf.Variable(tf.zeros([32, 32, 32]))\n",
    "    L1 = tf.nn.batch_normalization(L1, batch_mean, batch_var, beta, scale, 1e-3)\n",
    "    L1 = tf.nn.relu(L1)\n",
    "    # Pooling layer\n",
    "    L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Conv-2'):\n",
    "    W2 = tf.Variable(tf.random_normal([3, 3, 32, 128], stddev=0.01))\n",
    "    L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    batch_mean, batch_var = tf.nn.moments(L2, [0])\n",
    "    scale = tf.Variable(tf.ones([16, 16, 128]))\n",
    "    beta = tf.Variable(tf.zeros([16, 16, 128]))\n",
    "    L2 = tf.nn.batch_normalization(L2, batch_mean, batch_var, beta, scale, 1e-3)\n",
    "\n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Conv-3'):\n",
    "    W3 = tf.Variable(tf.random_normal([5, 5, 128, 256], stddev=0.01))\n",
    "    L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    batch_mean, batch_var = tf.nn.moments(L3, [0])\n",
    "    scale = tf.Variable(tf.ones([8, 8, 256]))\n",
    "    beta = tf.Variable(tf.zeros([8, 8, 256]))\n",
    "    L3 = tf.nn.batch_normalization(L3, batch_mean, batch_var, beta, scale, 1e-3)\n",
    "\n",
    "    L3 = tf.nn.relu(L3)\n",
    "    L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Full-1'):\n",
    "    W4 = tf.Variable(tf.random_normal([4 * 4 * 256, 256], stddev=0.01))\n",
    "    L4 = tf.reshape(L3, [-1, 4 * 4 * 256])\n",
    "    L4 = tf.matmul(L4, W4)\n",
    "    batch_mean, batch_var = tf.nn.moments(L4, [0])\n",
    "    scale = tf.Variable(tf.ones([256]))\n",
    "    beta = tf.Variable(tf.zeros([256]))\n",
    "    L4 = tf.nn.batch_normalization(L4, batch_mean, batch_var, beta, scale, 1e-3)\n",
    "    L4 = tf.nn.relu(L4)\n",
    "    # Dropout\n",
    "    L4 = tf.nn.dropout(L4, dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Full-2'):\n",
    "    W5 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "    model = tf.matmul(L4, W5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function, you can change the implementation\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch = 100\n",
    "total_batch = int(len(Xtr) / mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(start, end):\n",
    "    batch_xs = Xtr[start:end]\n",
    "    batch_ys = Ytr_onehot[start:end]\n",
    "    return batch_xs, batch_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  01 \tAvg cost:  1.137 \tAccuracy:  0.723\n",
      "Epoch:  02 \tAvg cost:  0.782 \tAccuracy:  0.755\n",
      "Epoch:  03 \tAvg cost:  0.614 \tAccuracy:  0.775\n",
      "Epoch:  04 \tAvg cost:  0.467 \tAccuracy:  0.788\n",
      "Epoch:  05 \tAvg cost:  0.340 \tAccuracy:  0.78\n",
      "Epoch:  06 \tAvg cost:  0.256 \tAccuracy:  0.773\n",
      "Epoch:  07 \tAvg cost:  0.184 \tAccuracy:  0.787\n",
      "Epoch:  08 \tAvg cost:  0.140 \tAccuracy:  0.774\n",
      "Epoch:  09 \tAvg cost:  0.120 \tAccuracy:  0.772\n",
      "Epoch:  10 \tAvg cost:  0.089 \tAccuracy:  0.792\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    total_cost = 0\n",
    "    \n",
    "    batch_start = 0\n",
    "    batch_end = mini_batch\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = next_batch(batch_start, batch_end)\n",
    "#         batch_xs = batch_xs.reshape(-1, 3136, 3136, 1)    # When image number is unknown put -1\n",
    "        _, curr_loss = sess.run([optimizer, cost],\n",
    "                                feed_dict={X: batch_xs, Y: batch_ys, dropout_prob: 0.7})\n",
    "        total_cost += curr_loss\n",
    "        batch_start += mini_batch\n",
    "        batch_end += mini_batch\n",
    "        \n",
    "    correctness = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctness, tf.float32))\n",
    "    print('Epoch: ', '%02d' % (epoch + 1),\n",
    "          '\\tAvg cost: ', '{:,.3f}'.format(total_cost / total_batch),\n",
    "          '\\tAccuracy: ', sess.run(accuracy, feed_dict={X: Xte[:1000],\n",
    "                                                      Y: Yte_onehot[:1000],\n",
    "                                                      dropout_prob: 1}))    # No dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
