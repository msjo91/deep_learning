SNU 4IRA
## Big Data Platform
### 1. 모델/알고리즘
+ 모듈  

모듈 | 용도
--- | ---
sklearn | RandomForestClassifier, confusion matrix
pandas | 데이터프레임
numpy | 새 카테고리 생성
collections | 결과 카운터

+ 모델

_`Random Forest Model`_  
> 여러 개의 decision tree(DT)를 임의적으로 학습하는 앙상블 방법이다. 단, 블랙박스이기 때문에 어떤 과정을 통해 학습결과가 나왔는지 확인할 수 없다.  
>> 1. 학습 및 테스트 알고리즘이 간편하고 빠르다.  
>> 2. 정확성이 높다.  
>> 3. 변수소거 전처리 없이 여러 변수를 다룰 수 있다.  
>> 4. 무작위성을 통한 훌륭한 일반화 성능을 보인다.  

### 2. 인자 탐색 과정 및 결과
RF를 사용했기 때문에 특별히 인자 탐색을 할 필요성을 느끼지는 않았다.

RF는 n 속성을 무작위로 선택하여 DT를 생성한 후 앙상블에 무작위성을 도입하고 DT 사이의 상관 관계를 줄인다. 따라서 n은 RF에서 조정할 수있는 주요 인자이다.

일반적으로 가장 좋은 n은 교차 검증으로 얻을 수 있다고 한다. 즉, 많이 돌려보고 비교해봐야한다는 말으로 보인다.

### 3. 데이터 조작 과정 및 결과
RF의 특성상 전처리가 필요없었다. 그래도 속성을 일부 제거하기로 했으며 의미를 알 수 없는 30개의 속성(V)은 알 수 없었기 때문에 남겨두었다. Time, Amount 속성은 전처리하거나 삭제할 필요는 없었으나 특별히 의미가 있는 것 같지 않았기 때문에 삭제하였다.  
만에 하나라도 결과가 애매하게 나오면 인자를 변경하거나 다른 모델을 사용할 용의가 있었으나 결과가 좋았기 때문에 그럴 필요가 없었다고 생각한다.

Confusion matrix는:

     | Predicted P | Predicted N
 --- | ----------- | -----------
 Actual P | 9897 | 3
 Actual N | 21 | 79

Accuracy는 0.9976이고, F1-score는 0.8681이다.

Test set를 모델에 넣어 prediction을 불러오고 result.csv에 있는 결과와 비교해봤을 때, 10000개의 record 중 결과가 다른 것은 16개뿐으로 이하 레코드가 test set의 실제 결과와 prediction이 다른 경우이다.

> 419, 639, 649, 1474, 2248, 2837, 3678, 3924, 5213, 6408, 6901, 7215, 7572, 8071, 8340, 8853
