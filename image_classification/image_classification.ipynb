{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearestNeighbor classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dataset file\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dataset and divide to train set and test set\n",
    "def load_CIFAR10(pos, n_chunks=1):\n",
    "    '''\n",
    "    Use data_batches (from data_batch_1) as training set and test_batch as test set\n",
    "    '''\n",
    "    Xtr = []\n",
    "    Ytr = []\n",
    "    for i in range(n_chunks):\n",
    "        train = unpickle(pos + '/data_batch_{}'.format(i + 1))\n",
    "        Xtr.extend(train[b'data'])\n",
    "        Ytr.extend(train[b'labels'])\n",
    "    test = unpickle(pos + '/test_batch')\n",
    "    Xte = test[b'data']\n",
    "    Yte = test[b'labels']\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Ytr, Xte, Yte = load_CIFAR10('cifar-10-batches-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Check type\n",
    "print(type(Xtr))\n",
    "print(type(Ytr))\n",
    "print(type(Xte))\n",
    "print(type(Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n",
      "(10000,)\n",
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Change list types to numpy array type\n",
    "Xtr = np.array(Xtr)\n",
    "Ytr = np.array(Ytr)\n",
    "Yte = np.array(Yte)\n",
    "# Get shape\n",
    "print(Xtr.shape)\n",
    "print(Ytr.shape)\n",
    "print(Xte.shape)\n",
    "print(Yte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Reshape (Seems pointless but explains how to use reshape method)\n",
    "Xtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3)\n",
    "Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3)\n",
    "print(Xtr_rows.shape)\n",
    "print(Xte_rows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3072)\n",
      "(1000,)\n",
      "(2000, 3072)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "# Validation set\n",
    "Xval_rows = Xtr_rows[:1000, :]\n",
    "Yval = Ytr[:1000]\n",
    "# Cut off training set because it will take a very long time\n",
    "# Probably the best to use all\n",
    "Xtr_rows = Xtr_rows[8000:, :]\n",
    "Ytr = Ytr[8000:]\n",
    "print(Xval_rows.shape)\n",
    "print(Yval.shape)\n",
    "print(Xtr_rows.shape)\n",
    "print(Ytr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution\n",
    "def compute_dist(X, point, dist_type):\n",
    "    if dist_type == 'l1':\n",
    "        # Manhattan norm\n",
    "        return np.sum(np.abs(X - point), axis=1)\n",
    "    elif dist_type == 'l2':\n",
    "        # Euclidean norm\n",
    "        return np.sqrt(np.sum(np.square(X - point), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict point\n",
    "def predict_point(distances, ytr, k):\n",
    "    if k == 1:\n",
    "        min_index = np.argmin(distances)\n",
    "        return ytr[min_index]\n",
    "    elif k > 1:\n",
    "        min_indices = np.argpartition(distances, k)[:k]\n",
    "        labels = np.array([ytr[i] for i in min_indices])\n",
    "        return np.argmax(np.bincount(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighbor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        self.Xtr = X\n",
    "        self.ytr = y\n",
    "        \n",
    "    def predict(self, X, k=1, dist_type='l1'):\n",
    "        num_test = X.shape[0]\n",
    "        Ypred = np.zeros(num_test, dtype=self.ytr.dtype)\n",
    "        \n",
    "        for i in range(num_test):\n",
    "            distances = compute_dist(self.Xtr, X[i,:], dist_type)\n",
    "            Ypred[i] = predict_point(distances, self.ytr, k)\n",
    "        return Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, dist_type: l1, accuracy: 0.202000\n",
      "k: 1, dist_type: l2, accuracy: 0.169000\n",
      "k: 3, dist_type: l1, accuracy: 0.177000\n",
      "k: 3, dist_type: l2, accuracy: 0.178000\n",
      "k: 5, dist_type: l1, accuracy: 0.181000\n",
      "k: 5, dist_type: l2, accuracy: 0.186000\n",
      "k: 10, dist_type: l1, accuracy: 0.187000\n",
      "k: 10, dist_type: l2, accuracy: 0.180000\n",
      "k: 20, dist_type: l1, accuracy: 0.181000\n",
      "k: 20, dist_type: l2, accuracy: 0.195000\n",
      "k: 50, dist_type: l1, accuracy: 0.173000\n",
      "k: 50, dist_type: l2, accuracy: 0.196000\n",
      "k: 100, dist_type: l1, accuracy: 0.167000\n",
      "k: 100, dist_type: l2, accuracy: 0.210000\n"
     ]
    }
   ],
   "source": [
    "validation_accuracies = []\n",
    "for k in [1, 3, 5, 10, 20, 50, 100]:\n",
    "    for dist_type in ['l1', 'l2']:\n",
    "        nn = NearestNeighbor()\n",
    "        nn.train(Xtr_rows, Ytr)\n",
    "        \n",
    "        Yval_predict = nn.predict(Xval_rows, k=k, dist_type=dist_type)\n",
    "        acc = np.mean(Yval_predict == Yval)\n",
    "        print('k: %d, dist_type: %s, accuracy: %f' % (k, dist_type, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tryout Ensemble (Unrelated to above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classifier packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random n-class classification problem\n",
    "# 1000 samples, 4 features, 0 informative features, 0 redundant features\n",
    "# np.random RNG, 0 classes, no shuffling sample or feature\n",
    "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2,\n",
    "                           n_redundant=0, random_state=0, n_classes=2,\n",
    "                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.17287856  0.80608704  0.01884792  0.00218648]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X, y)\n",
    "print(clf.feature_importances_)\n",
    "# Predict [0, 0, 0, 0](feature1=0, f2=0, f3=0, f4=0) class\n",
    "print(clf.predict([[0, 0, 0, 0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
