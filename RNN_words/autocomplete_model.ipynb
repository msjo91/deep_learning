{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple autocomplete model  \n",
    "Given 3 characters, pick the next logical, syntactical, semantical character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps\n",
    "1. Generate a dictionary of character-number {chr: num}  (character pool)\n",
    "2. Generate instances of length-4-words (training data)\n",
    "3. Generate batches (one-hot)\n",
    "4. Set hyperparameters\n",
    "5. Set placeholders\n",
    "6. Set variables\n",
    "7. Create LSTM cell\n",
    "8. Train\n",
    "9. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "char_arr = list('abcdefghijklmnopqrstuvwxyz')\n",
    "num_dic = {v: i for i, v in enumerate(char_arr)}\n",
    "dic_len = len(num_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "seq_data = ['word', 'wood', 'deep', 'dive', 'cold',\n",
    "            'cool', 'load', 'love', 'kiss', 'kind',\n",
    "            'deal', 'with', 'hate', 'halo', 'lone',\n",
    "            'home', 'baby', 'here', 'soup', 'crab',\n",
    "            'beam', 'bean', 'date', 'live', 'ring',\n",
    "            'data', 'rear', 'fear', 'peel', 'ping',\n",
    "            'beat', 'bite', 'sick', 'deem', 'tree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "def make_batch(seq_data):\n",
    "    input_batch, target_batch = [], []\n",
    "    \n",
    "    for seq in seq_data:\n",
    "        inpt = [num_dic[w] for w in seq[:-1]] # Remove fourth character\n",
    "        target = num_dic[seq[-1]] # Get only fourth character\n",
    "        # Each input number from num_dic becomes an one-hot vector\n",
    "        input_batch.append(np.eye(dic_len)[inpt]) # Create identity matrix\n",
    "        target_batch.append(target)\n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_batch(seq_data)[0][0] # First three characters in vector (input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 3,\n",
       " 15,\n",
       " 4,\n",
       " 3,\n",
       " 11,\n",
       " 3,\n",
       " 4,\n",
       " 18,\n",
       " 3,\n",
       " 11,\n",
       " 7,\n",
       " 4,\n",
       " 14,\n",
       " 4,\n",
       " 4,\n",
       " 24,\n",
       " 4,\n",
       " 15,\n",
       " 1,\n",
       " 12,\n",
       " 13,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 17,\n",
       " 17,\n",
       " 11,\n",
       " 6,\n",
       " 19,\n",
       " 4,\n",
       " 10,\n",
       " 12,\n",
       " 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_batch(seq_data)[1] # The fourth characters (target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "learning_rate = 0.01\n",
    "n_hidden = 128 # Number of hidden states\n",
    "total_epoch = 30\n",
    "n_step = 3 # Three characters to read\n",
    "n_input = n_class = dic_len # Number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5\n",
    "with tf.device('/gpu:0'): # Run with GPU\n",
    "    X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "    Y = tf.placeholder(tf.int32, [None])\n",
    "# Running with GPU is quite useless in this case because toy dataset is very small\n",
    "# and the structure is very simple.\n",
    "# But it is still written because, because. (Apparently just did  it for no reason.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7\n",
    "cell1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "# A cell with dropout is usually stronger against noise\n",
    "cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5) # Let 50% pass\n",
    "# A cell without dropout is usually stronger in clean dataset\n",
    "cell2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.matmul(outputs, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=Y)\n",
    ")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Cost = 3.646148\n",
      "Epoch: 002, Cost = 3.058766\n",
      "Epoch: 003, Cost = 2.426885\n",
      "Epoch: 004, Cost = 2.195904\n",
      "Epoch: 005, Cost = 1.678676\n",
      "Epoch: 006, Cost = 1.407809\n",
      "Epoch: 007, Cost = 1.166907\n",
      "Epoch: 008, Cost = 0.849741\n",
      "Epoch: 009, Cost = 0.733174\n",
      "Epoch: 010, Cost = 0.652847\n",
      "Epoch: 011, Cost = 0.490465\n",
      "Epoch: 012, Cost = 0.456534\n",
      "Epoch: 013, Cost = 0.540301\n",
      "Epoch: 014, Cost = 0.498168\n",
      "Epoch: 015, Cost = 0.389873\n",
      "Epoch: 016, Cost = 0.565789\n",
      "Epoch: 017, Cost = 0.505857\n",
      "Epoch: 018, Cost = 0.293771\n",
      "Epoch: 019, Cost = 0.480693\n",
      "Epoch: 020, Cost = 0.332685\n",
      "Epoch: 021, Cost = 0.379624\n",
      "Epoch: 022, Cost = 0.442641\n",
      "Epoch: 023, Cost = 0.411749\n",
      "Epoch: 024, Cost = 0.322995\n",
      "Epoch: 025, Cost = 0.404633\n",
      "Epoch: 026, Cost = 0.313116\n",
      "Epoch: 027, Cost = 0.360299\n",
      "Epoch: 028, Cost = 0.313611\n",
      "Epoch: 029, Cost = 0.249297\n",
      "Epoch: 030, Cost = 0.287757\n"
     ]
    }
   ],
   "source": [
    "# Step 8\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run([optimizer, cost],\n",
    "                       feed_dict={X: input_batch, Y: target_batch})\n",
    "    print('Epoch: {:03}, Cost = {:.6f}'.format(epoch + 1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9\n",
    "prediction = tf.cast(tf.argmax(model, 1), tf.int32)\n",
    "prediction_check = tf.equal(prediction, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_check, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted:  ['kil', 'fee', 'ben', 'ris']\n",
      "Predicted:  ['kild', 'feer', 'benm', 'risg']\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "test_data = ['kill', 'feel', 'bend', 'risk']\n",
    "\n",
    "input_batch, target_batch = make_batch(test_data)\n",
    "\n",
    "predict, accuracy_val = sess.run([prediction, accuracy],\n",
    "                                 feed_dict={X: input_batch, Y: target_batch})\n",
    "predict_words = []\n",
    "for idx, val in enumerate(test_data):\n",
    "    last_char = char_arr[predict[idx]]\n",
    "    predict_words.append(val[:3] + last_char)\n",
    "    \n",
    "print('Inserted: ', [w[:3] for w in test_data])\n",
    "print('Predicted: ', predict_words)\n",
    "print('Accuracy: ', accuracy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: Can't really expect any nice accuracy since toy dataset is too small to learn anything from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
